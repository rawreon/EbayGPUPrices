# Ebay prices of Sold Reference GPUs

<p align="center">
  <img width="700" height="432" src=/images/gpuprices.png>
</p>

Using selenium in python, I scraped the prices of sold reference GPUs off ebay into excel spreadsheets. I cleaned up the data in python and then visualized it using ggplot in R to make the graph above.

This project was inspired by [this](https://www.reddit.com/r/dataisbeautiful/comments/q9y3ne/oc_sale_prices_of_used_iphones/) post on /r/dataisbeautiful that I saw on the front page of reddit. I discovered that this was a sina plot and wanted to create my own graphic with this type of graph. The reddit post used the listing price of iphones on ebay, but I thought the price of completed sold items were more useful so I wanted to use that. I knew that graphics cards are being sold at a premium due to their shortage and so I want to see how much above MSRP graphics cards are being sold on Ebay. Reference GPUs are graphics cards manufactured by NVIDIA and AMD themselves. I decided to only look at reference cards for the most recent GPU generation as looking at every brand that makes multiple GPUs would have taken a lot longer. A few comments speculated about how the data was collected as the poster did not specify. The two main sources was using Ebay's API and webscraping. I decided to try using Ebay API's first.

## Using Ebay API and its limits
After creating an ebay developer account and applying for production API keys, I followed [this](https://www.youtube.com/watch?v=Ma_eLdobmlM) wonderful tutorial by Python 360. Using [ebaySDK](https://github.com/timotheus/ebaysdk-python) to make requests, I was able to sucessfully retrieve listings of GPUs. By specifying aspect filters and item filters in the parameters of my request, I retrieved the listings of only reference GPUs. However, this is when I ran into a bit of a problem. In turns out that Ebay's API was only able to return current listings and not completed sold listings. There was a parameter, SoldItemsOnly, that I could specify for item filter, but it was only a placeholder that was not functional. You used to be able to specify findCompletedItems in the request, but this call is depreciated and no longer useable. There exists a marketplace API, but in order to gain access you had to apply for business approval. At this point, I either had to use the listing prices like the reddit post, or find another avenue for collecting data. This led me to try webscraping in python.

## Obtaining data through webscraping using Selenium
Webscraping was not as complicated as I thought it would be and was actually kind of fun. It was mostly finding the right classes and ids to reference in a website's HTML.  Learning to automate actions on the web through the use of webdrivers was really cool to me. [This](https://www.youtube.com/watch?v=9ELd7XWD0PA) amazing tutorial by Jie Jenn provided the framework for my data collection of completed sold listings. There were a few roadblocks along the way of collecting my data with webscraping. The reference class for current listings is different for completed listings. It turned out the HTML class reference for completed listings also referenced an empty space before the listings started, and so when the code tried to look for data within that empty listing, it would stop functioning, returning nothing. It took a frustrating hour to figure this out. The easy fix for this was to just pop the first item of my listing array, thereby removing the empty listing and working with actual listings. Another problem, and the most annoying problem, I encountered was dealiong with CAPTCHA. Apparently when looking at sold completed listings, they would make the user finish a CAPTCHA before letting them access the page. After much research, I found no ways to circumvent the CAPTCHA. My solution to this problem was to set a timer after opening the specified URL in my code, before the webscraping starts. If there is a CAPTCHA, this timer allowed me to manually solve it, letting the webscraping function to collect data like normal.
